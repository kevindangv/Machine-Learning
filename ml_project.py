# -*- coding: utf-8 -*-
"""ml_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1El7nLtAZWiyzhni9E1dqr29ckIFt26h1

# Importing and Cleaning the Data
"""

from pandas.plotting import scatter_matrix # optional
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.compose import ColumnTransformer
import random

# Your code goes here for this section.
crashes = pd.read_csv("Virginia_Crashes.csv")
crashes.head()

crashes.info()

#Cleaning the data, dropping non-useful categories
crashes_cleaned = crashes.drop(['X', 'Y', 'OBJECTID', 'Document_Nbr', 'Local_Case_Cd',
                                'Passinjurytype', 'Passage', 'Route_Or_Street_Nm',
                                'Passgen', 'Pedinjurytype', 'Pedage', 'Pedgen', 'Node_Info',
                                'DIAGRAM', 'MPO_NAME', 'Crash_Dt', 'Vehicle_Body_Type_Cd',
                                'Driverinjurytype', 'Driverage', 'Drivergen', 'Rte_Nm', 'Physical_Juris',
                                'Fatal_Crashes', 'Pedestrians_Killed', 'Pedestrians_Injured',
                                'K_People', 'A_People', 'B_People', 'C_People', 'A_Crash',
                                'B_Crash', 'C_Crash', 'Pdo_Crash'], axis=1)
crashes_cleaned["Bike_Nonbike"].fillna("No Bike", inplace = True)
crashes_cleaned["Motor_Nonmotor"].fillna("No Moter", inplace = True)
crashes_cleaned["Speed_Notspeed"].fillna("Not Speeding", inplace = True)
crashes_cleaned["Belted_Unbelted"].fillna("Belted", inplace = True)
crashes_cleaned["Alcohol_Notalcohol"].fillna("No Alcohol", inplace = True)
crashes_cleaned["Young_Notyoung"].fillna("Not Young", inplace = True)
crashes_cleaned["Senior_Notsenior"].fillna("Not Senior", inplace = True)
crashes_cleaned["Deer_Nodeer"].fillna("No Deer", inplace = True)
crashes_cleaned["Distracted_Notdistracted"].fillna("Not Distracted", inplace = True)
crashes_cleaned = crashes_cleaned[crashes_cleaned.LATITUDE != 0]
crashes_cleaned['Driver_Action_Type_Cd'] = crashes_cleaned['Driver_Action_Type_Cd'].str.split().str[0].str.strip()
crashes_cleaned.head()

crashes_cleaned.plot(kind="scatter", x="LONGITUDE", y="LATITUDE", alpha=0.005, figsize=(14,7), sharex=False, )
plt.legend()

crashes_cleaned.info()

crashes_cleaned = crashes_cleaned.dropna()
sample_incomplete_rows = crashes_cleaned[crashes_cleaned.isnull().any(axis=1)]
sample_incomplete_rows

from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import MinMaxScaler

num_attribs = num_attribs = ["Crash_Year", 
                             "Crash_Military_Tm", "Rns_Mp", 
                             "Carspeedlimit", "LATITUDE", "LONGITUDE", "VSP"]

cat_attribs = ["Collision_Type", "Roadway_Surface_Cond", "First_Harmful_Event_of_Entire", "Weather_Condition", "Light_Condition", 
               "School_Zone", "Crash_Severity", "Ped_Nonped", "Bike_Nonbike", "Motor_Nonmotor", "Speed_Notspeed", "Belted_Unbelted", 
               "Alcohol_Notalcohol", "Rd_Type", "Crash_Event_Type_Dsc", "Time_Slicing", "Vehiclenumber", "Driver_Action_Type_Cd",
               "Young_Notyoung", "Senior_Notsenior", "Ownership", "SYSTEM", "FUN", "FAC", "Deer_Nodeer", "Distracted_Notdistracted",
               "VDOT_District", "PLAN_DISTRICT"]

num_pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy="median")),
        ('std_scaler', StandardScaler())
    ])

cat_pipeline = Pipeline([
        ('ord_encoder', OrdinalEncoder()),
        #('std_scaler', MinMaxScaler(feature_range=(0,9)))             
    ])

full_pipeline = ColumnTransformer([
        ("num", num_pipeline, num_attribs),
        ("cat", cat_pipeline, cat_attribs)
    ])

crashes_prepared = full_pipeline.fit_transform(crashes_cleaned)
crashes_prepared.shape

from sklearn.model_selection import train_test_split

train_set, test_set = train_test_split(crashes_prepared, test_size=0.2, random_state=42)

y_train = train_set[:,13]
x_train = np.delete(train_set, 13, axis=1)
y_test = test_set[:, 13]
x_test = np.delete(test_set, 13, axis=1)
np.unique(y_train)

"""# Clustering"""

from sklearn.cluster import MiniBatchKMeans
kmeans = MiniBatchKMeans(n_clusters=2)
kmeans.fit(crashes_prepared)
y_kmeans = kmeans.predict(crashes_prepared)

plt.figure(figsize=(14, 7))
plt.scatter(crashes_prepared[:, 5], crashes_prepared[:, 4], c=y_kmeans, cmap='rainbow', alpha=0.02)
centers = kmeans.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='yellow', s=200, alpha=1.0);
#2 colors: red, purple

kmeans = MiniBatchKMeans(n_clusters=3)
kmeans.fit(crashes_prepared)
y_kmeans = kmeans.predict(crashes_prepared)

plt.figure(figsize=(14, 7))
plt.scatter(crashes_prepared[:, 5], crashes_prepared[:, 4], c=y_kmeans, cmap='rainbow', alpha=0.02)
centers = kmeans.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='yellow', s=200, alpha=1.0);
#3 colors: green, purple, red

kmeans = MiniBatchKMeans(n_clusters=4)
kmeans.fit(crashes_prepared)
y_kmeans = kmeans.predict(crashes_prepared)

plt.figure(figsize=(14, 7))
plt.scatter(crashes_prepared[:, 5], crashes_prepared[:, 4], c=y_kmeans, cmap='rainbow', alpha=0.02)
centers = kmeans.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='yellow', s=200, alpha=1.0);
#4 colors: blue, purple, yellow, orange

kmeans = MiniBatchKMeans(n_clusters=5, n_init=100)
kmeans.fit(crashes_prepared)
y_kmeans = kmeans.predict(crashes_prepared)

plt.figure(figsize=(14, 7))
plt.scatter(crashes_prepared[:, 5], crashes_prepared[:, 4], c=y_kmeans, cmap='rainbow', alpha=0.02)
centers = kmeans.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='yellow', s=200, alpha=1.0);
#5 colors: purple, blue, orange, yellow, pink

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = MiniBatchKMeans(n_clusters=k, n_init=100)
    km = km.fit(crashes_prepared)
    Sum_of_squared_distances.append(km.inertia_)

plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
plt.savefig('plot.png')

"""# ANN"""

x_train_ann, x_val_ann, y_train_ann, y_val_ann = train_test_split(x_train, y_train, test_size= 0.1, random_state=49)

from tensorflow import keras
from keras.layers import Activation, Dense

my_model = keras.models.Sequential([
    keras.layers.Flatten(),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(300, use_bias=False),
    keras.layers.BatchNormalization(),
    keras.layers.Activation("relu"),
    keras.layers.Dense(100, use_bias=False),
    keras.layers.Activation("relu"),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(5, activation="softmax")
])

my_model.compile(optimizer=keras.optimizers.SGD(lr=1e-3),
              loss="sparse_categorical_crossentropy",
              metrics=['accuracy'])

my_model.fit(x_train_ann, y_train_ann, validation_data = (x_val_ann, y_val_ann), epochs = 10)

my_model.evaluate(x = x_test, y = y_test)

"""# SVM Model"""

from sklearn.svm import SVC
from sklearn.ensemble import BaggingClassifier
from sklearn.multiclass import OneVsRestClassifier

n_estimators = 34
clf = OneVsRestClassifier(BaggingClassifier(SVC(kernel='linear', probability=True, 
                                                class_weight='balanced'), max_samples=1.0 / n_estimators, n_estimators=n_estimators))

clf.fit(x_val_ann, y_val_ann)

y_pred = clf.predict(x_test)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_pred))

"""# Linear Regression"""

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(x_train, y_train)

from sklearn.metrics import mean_squared_error
y_predict = lin_reg.predict(x_test)
mse = mean_squared_error(y_test, y_predict)
lin_reg_rmse = np.sqrt(mse)
print("SKlearn Model RMSE: " + str(lin_reg_rmse))

"""# Random Forest"""

from sklearn.ensemble import RandomForestRegressor

forest_reg = RandomForestRegressor()
forest_reg.fit(x_train, y_train)

y_pred = forest_reg.predict(x_test)
forest_mse = mean_squared_error(y_pred, y_test)
forest_rmse = np.sqrt(forest_mse)
forest_rmse

"""# Decision Tree"""

from sklearn.tree import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor(random_state=42, min_samples_leaf=20)
tree_reg.fit(x_train, y_train)

y_pred = tree_reg.predict(x_test)
tree_mse = mean_squared_error(y_pred, y_test)
tree_rmse = np.sqrt(tree_mse)
tree_rmse

